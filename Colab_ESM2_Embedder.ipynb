{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYn9RVAJMLbl"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Step 0: Mount Google Drive\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# =========================\n",
        "# Step 1: Install dependencies\n",
        "# =========================\n",
        "!apt-get install -y prodigal > /dev/null\n",
        "!pip install fair-esm biopython --quiet\n",
        "\n",
        "# =========================\n",
        "# Step 2: Imports\n",
        "# =========================\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import subprocess\n",
        "import torch\n",
        "import esm\n",
        "import numpy as np\n",
        "from Bio import SeqIO\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# =========================\n",
        "# Step 3: Colab input boxes\n",
        "# =========================\n",
        "input_fasta_dir_widget = widgets.Text(\n",
        "    value='/content/drive/MyDrive/Average_Structural_ID/ASI_Fasta_Files/ASI_Fasta_Files_Trial',\n",
        "    description='Input FASTA Dir:',\n",
        "    layout=widgets.Layout(width='90%')\n",
        ")\n",
        "\n",
        "esm_root_dir_widget = widgets.Text(\n",
        "    value='/content/drive/MyDrive/Average_Structural_ID/ESM2_npz_outputs',\n",
        "    description='Output NPZ Dir:',\n",
        "    layout=widgets.Layout(width='90%')\n",
        ")\n",
        "\n",
        "progress_json_widget = widgets.Text(\n",
        "    value='/content/drive/MyDrive/Average_Structural_ID/esm2_progress.json',\n",
        "    description='Progress JSON:',\n",
        "    layout=widgets.Layout(width='90%')\n",
        ")\n",
        "\n",
        "display(input_fasta_dir_widget, esm_root_dir_widget, progress_json_widget)\n",
        "\n",
        "input(\"Press Enter after confirming paths above...\")\n",
        "\n",
        "input_fasta_dir = input_fasta_dir_widget.value\n",
        "esm_root_dir = esm_root_dir_widget.value\n",
        "progress_json = progress_json_widget.value\n",
        "\n",
        "os.makedirs(esm_root_dir, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# Step 4: Load / initialize progress\n",
        "# =========================\n",
        "if os.path.exists(progress_json):\n",
        "    with open(progress_json) as f:\n",
        "        progress = json.load(f)\n",
        "else:\n",
        "    progress = {\"completed\": [], \"failed\": []}\n",
        "\n",
        "# =========================\n",
        "# Step 5: Load ESM2 model\n",
        "# =========================\n",
        "model_name = \"esm2_t6_8M_UR50D\"\n",
        "MAX_LEN = 2000\n",
        "BATCH_SIZE = 12  # adjust for GPU memory\n",
        "\n",
        "print(\"Loading ESM2 model...\")\n",
        "model, alphabet = esm.pretrained.load_model_and_alphabet(model_name)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "\n",
        "# =========================\n",
        "# Step 6: Helper functions\n",
        "# =========================\n",
        "def clean_sequence(seq: str) -> str:\n",
        "    allowed = set(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "    return \"\".join(aa if aa in allowed else \"X\" for aa in seq)\n",
        "\n",
        "def read_faa(faa_path):\n",
        "    return [(record.id, clean_sequence(str(record.seq))) for record in SeqIO.parse(faa_path, \"fasta\")]\n",
        "\n",
        "def save_progress():\n",
        "    with open(progress_json, \"w\") as f:\n",
        "        json.dump(progress, f, indent=2)\n",
        "\n",
        "# =========================\n",
        "# Step 7: Process genomes\n",
        "# =========================\n",
        "fasta_files = sorted(f for f in os.listdir(input_fasta_dir) if f.lower().endswith((\".fasta\", \".fa\", \".fna\")))\n",
        "print(f\"Found {len(fasta_files)} FASTA files\")\n",
        "\n",
        "for fasta_name in fasta_files:\n",
        "    if fasta_name in progress[\"completed\"]:\n",
        "        print(f\"‚è≠Ô∏è Skipping completed genome ‚Üí {fasta_name}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"\\nüöÄ Processing genome ‚Üí {fasta_name}\")\n",
        "    genome_fasta = os.path.join(input_fasta_dir, fasta_name)\n",
        "\n",
        "    try:\n",
        "        base_name = re.sub(r\"[^\\w.-]\", \"_\", os.path.splitext(fasta_name)[0])\n",
        "        faa_file = os.path.join(input_fasta_dir, f\"{base_name}.faa\")\n",
        "        gff_file = os.path.join(input_fasta_dir, f\"{base_name}.gff\")\n",
        "        genome_npz_file = os.path.join(esm_root_dir, f\"{base_name}_esm2.npz\")\n",
        "\n",
        "        print(\"Running Prodigal...\")\n",
        "        subprocess.run([\"prodigal\", \"-i\", genome_fasta, \"-a\", faa_file, \"-o\", gff_file, \"-p\", \"single\"], check=True)\n",
        "        if not os.path.exists(faa_file):\n",
        "            raise FileNotFoundError(f\"Prodigal did not create {faa_file}\")\n",
        "\n",
        "        sequences = read_faa(faa_file)\n",
        "        print(f\"Embedding {len(sequences)} proteins...\")\n",
        "\n",
        "        all_embeddings = {}\n",
        "        for i in tqdm(range(0, len(sequences), BATCH_SIZE), desc=\"Batches\"):\n",
        "            batch_seqs = sequences[i:i+BATCH_SIZE]\n",
        "            batch_filtered = [(pid, seq) for pid, seq in batch_seqs if len(seq) <= MAX_LEN]\n",
        "            if not batch_filtered:\n",
        "                continue\n",
        "\n",
        "            batch_labels, batch_strs = zip(*batch_filtered)\n",
        "            _, _, batch_tokens = batch_converter(batch_filtered)\n",
        "            batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                results = model(batch_tokens, repr_layers=[6], return_contacts=False)\n",
        "            token_embeddings = results[\"representations\"][6]\n",
        "\n",
        "            for idx, pid in enumerate(batch_labels):\n",
        "                seq_len = len(batch_strs[idx])\n",
        "                embedding = token_embeddings[idx, 1:seq_len+1].mean(0).cpu().numpy()\n",
        "                all_embeddings[pid] = embedding\n",
        "\n",
        "            del batch_tokens, results, token_embeddings\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "        np.savez_compressed(genome_npz_file, **all_embeddings)\n",
        "\n",
        "        for tmp in (faa_file, gff_file):\n",
        "            if os.path.exists(tmp):\n",
        "                os.remove(tmp)\n",
        "\n",
        "        progress[\"completed\"].append(fasta_name)\n",
        "        save_progress()\n",
        "        print(f\"‚úÖ Finished genome ‚Üí {fasta_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed genome ‚Üí {fasta_name}\")\n",
        "        print(e)\n",
        "        progress[\"failed\"].append(fasta_name)\n",
        "        save_progress()\n",
        "\n",
        "print(\"\\nüéâ All available genomes processed!\")\n"
      ]
    }
  ]
}